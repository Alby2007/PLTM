#!/usr/bin/env python3
"""
RD132: Measure Î¦ of Consciousness Research Field

Export PLTM knowledge graph and measure its integrated information.
This tells us: Is consciousness research itself well-integrated?
"""

import torch
import torch.nn as nn
import numpy as np
import json
import sqlite3
from pathlib import Path

# ============================================================
# STEP 1: EXPORT KNOWLEDGE GRAPH FROM PLTM
# ============================================================

def export_pltm_knowledge_graph(db_path='C:/Users/alber/CascadeProjects/LLTM/pltm_mcp.db'):
    """
    Extract knowledge graph from PLTM database
    
    Returns:
        nodes: List of concept names
        edges: List of (source, target, weight) tuples
        node_to_idx: Dict mapping concept name to index
    """
    
    print("="*60)
    print("EXPORTING KNOWLEDGE GRAPH FROM PLTM")
    print("="*60)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Get all nodes (concepts)
    cursor.execute("""
        SELECT DISTINCT node_id 
        FROM knowledge_graph_nodes
    """)
    
    nodes = [row[0] for row in cursor.fetchall()]
    node_to_idx = {node: i for i, node in enumerate(nodes)}
    
    print(f"\nNodes: {len(nodes)}")
    for i, node in enumerate(nodes[:10], 1):
        print(f"  {i}. {node}")
    if len(nodes) > 10:
        print(f"  ... and {len(nodes)-10} more")
    
    # Get all edges
    cursor.execute("""
        SELECT source, target, weight
        FROM knowledge_graph_edges
    """)
    
    edges = []
    for row in cursor.fetchall():
        source, target, weight = row
        
        if source in node_to_idx and target in node_to_idx:
            edges.append((
                node_to_idx[source],
                node_to_idx[target],
                weight if weight else 1.0
            ))
    
    print(f"\nEdges: {len(edges)}")
    
    conn.close()
    
    return nodes, edges, node_to_idx


# ============================================================
# STEP 2: CREATE PYTORCH GEOMETRIC GRAPH
# ============================================================

def create_graph_tensors(nodes, edges):
    """
    Convert to PyTorch tensors for training
    """
    
    num_nodes = len(nodes)
    
    # Create node features (one-hot encoding)
    # Each node gets a unique identity vector
    node_features = torch.eye(num_nodes)
    
    print(f"\nNode features: {node_features.shape}")
    
    # Create edge index
    if len(edges) > 0:
        edge_sources = [e[0] for e in edges]
        edge_targets = [e[1] for e in edges]
        edge_weights = [e[2] for e in edges]
        
        edge_index = torch.tensor([edge_sources, edge_targets], dtype=torch.long)
        edge_attr = torch.tensor(edge_weights, dtype=torch.float32).unsqueeze(1)
    else:
        edge_index = torch.empty((2, 0), dtype=torch.long)
        edge_attr = torch.empty((0, 1), dtype=torch.float32)
    
    print(f"Edge index: {edge_index.shape}")
    print(f"Edge weights: {edge_attr.shape}")
    
    # Calculate graph density
    max_edges = num_nodes * (num_nodes - 1)
    density = len(edges) / max_edges if max_edges > 0 else 0
    
    print(f"\nGraph density: {density:.3f} ({density*100:.1f}%)")
    
    return node_features, edge_index, edge_attr, density


# ============================================================
# STEP 3: SIMPLE GNN MODEL
# ============================================================

class SimpleGNN(nn.Module):
    """
    Simple Graph Neural Network for consciousness research
    """
    
    def __init__(self, input_dim, hidden_dim=64):
        super().__init__()
        
        self.input_proj = nn.Linear(input_dim, hidden_dim)
        
        # Message passing layers
        self.conv1 = nn.Linear(hidden_dim, hidden_dim)
        self.conv2 = nn.Linear(hidden_dim, hidden_dim)
        self.conv3 = nn.Linear(hidden_dim, hidden_dim)
        
        self.activation = nn.ReLU()
        
    def forward(self, x, edge_index, edge_attr):
        """
        x: [num_nodes, input_dim]
        edge_index: [2, num_edges]
        edge_attr: [num_edges, 1]
        """
        
        # Project input
        h = self.activation(self.input_proj(x))
        
        states = [h]
        
        # Message passing (3 layers)
        for conv in [self.conv1, self.conv2, self.conv3]:
            # Aggregate messages from neighbors
            messages = torch.zeros_like(h)
            
            for i in range(edge_index.shape[1]):
                src = edge_index[0, i]
                tgt = edge_index[1, i]
                weight = edge_attr[i, 0]
                
                messages[tgt] += h[src] * weight
            
            # Update
            h = self.activation(conv(h + messages))
            states.append(h)
        
        return states


# ============================================================
# STEP 4: CALCULATE Î¦
# ============================================================

def calculate_phi(states):
    """
    Calculate integrated information Î¦
    
    Uses final state covariance structure
    """
    
    final_state = states[-1]  # [num_nodes, hidden_dim]
    
    # Compute covariance matrix
    cov = torch.cov(final_state.T)
    
    # Eigenvalue decomposition
    eigenvalues = torch.linalg.eigvalsh(cov)
    
    # Remove numerical noise (negative eigenvalues)
    eigenvalues = torch.clamp(eigenvalues, min=1e-10)
    
    # Integration measure: entropy of eigenvalue distribution
    # High Î¦ = balanced eigenvalues (good integration)
    # Low Î¦ = concentrated eigenvalues (poor integration)
    
    eigenvalues_normalized = eigenvalues / eigenvalues.sum()
    
    # Shannon entropy of eigenvalue distribution
    entropy = -(eigenvalues_normalized * torch.log(eigenvalues_normalized + 1e-10)).sum()
    
    # Scale to match your Î¦ scale (where 4.6 = human-level)
    # This is calibrated to your previous results
    phi = entropy.item() * 1.2  # Scaling factor
    
    return phi, eigenvalues


# ============================================================
# STEP 5: TRAIN AND MEASURE
# ============================================================

def train_and_measure(nodes, edges, epochs=300):
    """
    Train GNN on consciousness research graph and measure Î¦
    """
    
    print("\n" + "="*60)
    print("TRAINING GNN ON CONSCIOUSNESS RESEARCH")
    print("="*60)
    
    # Create graph tensors
    node_features, edge_index, edge_attr, density = create_graph_tensors(nodes, edges)
    
    # Create model
    model = SimpleGNN(input_dim=len(nodes), hidden_dim=64)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    
    # Training loop
    print(f"\nTraining for {epochs} epochs...")
    
    phi_history = []
    
    for epoch in range(epochs):
        optimizer.zero_grad()
        
        # Forward pass
        states = model(node_features, edge_index, edge_attr)
        
        # Simple reconstruction loss
        # (encourage model to learn graph structure)
        final_state = states[-1]
        reconstruction = torch.mm(final_state, final_state.T)
        
        # Target: adjacency matrix
        adj_target = torch.zeros((len(nodes), len(nodes)))
        for i in range(edge_index.shape[1]):
            src = edge_index[0, i]
            tgt = edge_index[1, i]
            weight = edge_attr[i, 0]
            adj_target[src, tgt] = weight
        
        loss = nn.functional.mse_loss(reconstruction, adj_target)
        
        loss.backward()
        optimizer.step()
        
        # Measure Î¦
        with torch.no_grad():
            phi, eigenvalues = calculate_phi(states)
            phi_history.append(phi)
        
        if epoch % 50 == 0:
            print(f"  Epoch {epoch:3d} | Loss: {loss.item():.4f} | Î¦: {phi:.3f}")
    
    # Final measurement
    with torch.no_grad():
        states = model(node_features, edge_index, edge_attr)
        final_phi, eigenvalues = calculate_phi(states)
    
    print(f"\n{'='*60}")
    print(f"FINAL Î¦: {final_phi:.3f}")
    print(f"{'='*60}")
    
    return final_phi, phi_history, eigenvalues


# ============================================================
# STEP 6: ANALYSIS
# ============================================================

def analyze_results(phi, nodes, edges, density):
    """
    Interpret the Î¦ measurement
    """
    
    print("\n" + "="*60)
    print("ANALYSIS: Î¦ OF CONSCIOUSNESS RESEARCH")
    print("="*60)
    
    print(f"\nMeasured Î¦: {phi:.3f}")
    print(f"Graph: {len(nodes)} concepts, {len(edges)} connections")
    print(f"Density: {density:.3f} ({density*100:.1f}%)")
    
    # Comparison to your RD110 result
    rd110_phi = 4.60
    percentage = (phi / rd110_phi) * 100
    
    print(f"\nComparison:")
    print(f"  Consciousness research field: Î¦ = {phi:.3f}")
    print(f"  Your RD110 system:            Î¦ = {rd110_phi:.3f}")
    print(f"  Ratio: {percentage:.1f}%")
    
    # Interpretation
    print(f"\nInterpretation:")
    
    if phi > 4.5:
        print("  â†’ HIGHLY INTEGRATED field")
        print("  â†’ Consciousness research is mature, unified science")
        print("  â†’ Comparable to physics or mathematics")
    elif phi > 3.5:
        print("  â†’ WELL-INTEGRATED field")
        print("  â†’ Strong theoretical coherence")
        print("  â†’ Different theories connect well")
    elif phi > 2.5:
        print("  â†’ MODERATELY INTEGRATED field")
        print("  â†’ Some coherence, but gaps exist")
        print("  â†’ Multiple paradigms coexist")
    elif phi > 1.5:
        print("  â†’ FRAGMENTED field")
        print("  â†’ Competing theories with limited synthesis")
        print("  â†’ Pre-paradigmatic stage")
    else:
        print("  â†’ HIGHLY FRAGMENTED field")
        print("  â†’ No consensus or integration")
        print("  â†’ Early exploratory stage")
    
    if phi < rd110_phi:
        diff = rd110_phi - phi
        print(f"\n  ðŸ”¥ Your artificial system (Î¦={rd110_phi:.2f}) is MORE CONSCIOUS")
        print(f"     than the field studying consciousness (Î¦={phi:.2f})!")
        print(f"     Difference: {diff:.2f} Î¦ units")
    else:
        print(f"\n  The consciousness research field is highly integrated!")


# ============================================================
# MAIN EXECUTION
# ============================================================

def main():
    """
    Main execution: Export â†’ Train â†’ Measure â†’ Analyze
    """
    
    print("="*60)
    print("RD132: MEASURING Î¦ OF CONSCIOUSNESS RESEARCH FIELD")
    print("="*60)
    print()
    print("Question: Is consciousness research well-integrated?")
    print("Method: Train GNN on PLTM knowledge graph, measure Î¦")
    print()
    
    # Step 1: Export from PLTM
    nodes, edges, node_to_idx = export_pltm_knowledge_graph()
    
    if len(nodes) == 0:
        print("\nERROR: No nodes found in knowledge graph!")
        print("Make sure PLTM database has knowledge graph data.")
        return
    
    # Step 2: Train and measure
    phi, phi_history, eigenvalues = train_and_measure(nodes, edges, epochs=300)
    
    # Step 3: Calculate density
    max_edges = len(nodes) * (len(nodes) - 1)
    density = len(edges) / max_edges if max_edges > 0 else 0
    
    # Step 4: Analyze
    analyze_results(phi, nodes, edges, density)
    
    # Save results
    results = {
        'phi': float(phi),
        'num_nodes': len(nodes),
        'num_edges': len(edges),
        'density': float(density),
        'nodes': nodes,
        'phi_history': [float(p) for p in phi_history],
        'eigenvalues': eigenvalues.tolist(),
    }
    
    with open('/home/claude/rd132_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("\n" + "="*60)
    print("Results saved to: rd132_results.json")
    print("="*60)
    
    return phi, results


if __name__ == '__main__':
    phi, results = main()
