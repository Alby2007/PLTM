# Experiments Quickstart

7 novel AI applications demonstrating the Procedural LTM system's capabilities.

---

## üéØ Overview

Each experiment showcases a unique use case for long-term memory with conflict resolution:

1. **Lifelong Learning Agent** - Learns and adapts over time
2. **Multi-Agent Workspace** - Shared memory across agents
3. **Temporal Reasoning** - Time-aware memory management
4. **Personalized Tutor** - Adaptive teaching based on history
5. **Contextual Copilot** - Context-aware code assistance
6. **Memory-Aware RAG** - Enhanced retrieval with conflict resolution
7. **Adaptive Prompts** - Dynamic prompt generation from memory

---

## üöÄ Quick Start (5 minutes)

### Run All Experiments

```bash
# Simple test runner (recommended)
python test_all_experiments_simple.py

# Expected output:
# ‚úÖ Lifelong Learning Agent
# ‚úÖ Multi-Agent Workspace
# ‚úÖ Temporal Reasoning
# ‚úÖ Personalized Tutor
# ‚úÖ Contextual Copilot
# ‚úÖ Memory-Aware RAG
# ‚ö†Ô∏è Adaptive Prompts (requires LLM)

# Result: 6/7 passing (85.7%)
```

### Run Individual Experiment

```bash
# Example: Lifelong Learning Agent
python -c "
from src.agents.lifelong_learning_agent import LifelongLearningAgent
from src.storage.sqlite_store import SQLiteGraphStore
from src.pipeline.memory_pipeline import MemoryPipeline

async def demo():
    store = SQLiteGraphStore(':memory:')
    await store.connect()
    pipeline = MemoryPipeline(store)
    agent = LifelongLearningAgent('alice', pipeline)
    
    # Agent learns over time
    await agent.learn('I love Python programming')
    await agent.learn('I work at Google')
    await agent.learn('I prefer functional programming')
    
    # Agent recalls relevant memories
    memories = await agent.recall('What do I like?')
    print(memories)

import asyncio
asyncio.run(demo())
"
```

---

## üìö Experiment Details

### 1. Lifelong Learning Agent

**What it does:** Agent that learns from interactions and maintains consistent memory over time.

**Key Features:**
- Learns from natural language input
- Recalls relevant memories for context
- Resolves contradictions automatically
- Adapts behavior based on history

**Use Case:** Personal AI assistant that remembers preferences and learns over time.

**Code:** `src/agents/lifelong_learning_agent.py`

**Example:**
```python
agent = LifelongLearningAgent('alice', pipeline)

# Day 1
await agent.learn("I love coffee")
await agent.learn("I work at Google")

# Day 30
await agent.learn("I hate coffee")  # Conflict detected!
# System: Resolves to newer preference

# Later
context = await agent.recall("What are my preferences?")
# Returns: "I hate coffee" (newer), "I work at Google"
```

---

### 2. Multi-Agent Workspace

**What it does:** Multiple agents share a common memory workspace with conflict resolution.

**Key Features:**
- Shared memory across agents
- Agent-specific capabilities
- Conflict resolution when agents disagree
- Collaborative learning

**Use Case:** Team of AI agents working together on a project.

**Code:** `src/agents/multi_agent_workspace.py`

**Example:**
```python
workspace = SharedMemoryWorkspace(pipeline)

# Add agents with different capabilities
workspace.add_agent("researcher", ["research", "analysis"])
workspace.add_agent("writer", ["writing", "editing"])

# Agents collaborate
await workspace.process("researcher", "Python is fast")
await workspace.process("writer", "Python is slow")
# System: Detects conflict, resolves based on agent expertise
```

---

### 3. Temporal Reasoning

**What it does:** Time-aware memory management with decay and temporal supersession.

**Key Features:**
- Time-based memory decay
- Temporal supersession (newer facts override older)
- Historical tracking
- Time-range queries

**Use Case:** Systems that need to track how information changes over time.

**Code:** `src/temporal/decay_manager.py`

**Example:**
```python
# January: User prefers Python
await pipeline.process_message("I prefer Python", user_id="alice")

# June: User changes preference
await pipeline.process_message("I prefer Rust", user_id="alice")

# System automatically:
# 1. Detects temporal conflict
# 2. Supersedes old preference with new
# 3. Moves old fact to historical graph
# 4. Maintains timeline for analysis
```

---

### 4. Personalized Tutor

**What it does:** Adaptive teaching system that personalizes based on student history.

**Key Features:**
- Tracks student knowledge level
- Adapts difficulty based on performance
- Remembers learning style preferences
- Identifies knowledge gaps

**Use Case:** Educational AI that personalizes to each student.

**Code:** `src/agents/personalized_tutor.py`

**Example:**
```python
tutor = PersonalizedTutor("student_123", pipeline)

# Student learns
await tutor.teach("Python basics")
await tutor.assess("Python basics", score=0.9)  # High score

# Tutor adapts
next_lesson = await tutor.recommend_next()
# Returns: "Advanced Python" (adapts to skill level)

# Student struggles
await tutor.assess("Async programming", score=0.4)
# Tutor: Recommends review materials, adjusts difficulty
```

---

### 5. Contextual Copilot

**What it does:** Code assistant that remembers project context and coding style.

**Key Features:**
- Remembers project structure
- Learns coding style preferences
- Recalls past decisions and patterns
- Context-aware suggestions

**Use Case:** AI pair programmer that knows your codebase.

**Code:** `src/agents/contextual_copilot.py`

**Example:**
```python
copilot = ContextualCopilot("developer_456", pipeline)

# Copilot learns preferences
await copilot.observe("User prefers functional style")
await copilot.observe("Project uses TypeScript")
await copilot.observe("User avoids classes")

# Later, when suggesting code
suggestion = await copilot.suggest("Create a data transformer")
# Returns: Functional TypeScript, no classes (matches preferences)
```

---

### 6. Memory-Aware RAG

**What it does:** Retrieval-Augmented Generation enhanced with conflict-resolved memory.

**Key Features:**
- Combines document retrieval with memory
- Resolves conflicts between sources
- Maintains consistent knowledge base
- Temporal awareness of information

**Use Case:** QA system that maintains consistent answers over time.

**Code:** `src/agents/memory_aware_rag.py`

**Example:**
```python
rag = MemoryAwareRAG(pipeline, document_store)

# User asks question
answer = await rag.query("What is our pricing?")
# System:
# 1. Retrieves relevant docs
# 2. Checks memory for conflicts
# 3. Resolves to most recent/authoritative
# 4. Returns consistent answer

# Later, pricing changes
await rag.update("New pricing: $99/month")
# System: Detects conflict with old pricing, supersedes
```

---

### 7. Adaptive Prompts

**What it does:** Dynamically generates prompts based on user history and preferences.

**Key Features:**
- Infers user expertise level
- Adapts communication style
- Personalizes examples
- Learns from feedback

**Use Case:** LLM interface that adapts to each user.

**Code:** `src/agents/adaptive_prompts.py`

**Example:**
```python
prompt_system = AdaptivePromptSystem("user_789", pipeline)

# System learns about user
await pipeline.process_message("I'm a beginner at Python", user_id="user_789")

# Generate personalized prompt
prompt = await prompt_system.generate_prompt(
    task="Explain async/await",
    include_examples=True
)

# Returns: Beginner-friendly explanation with simple examples

# After user gains experience
await pipeline.process_message("I understand decorators now", user_id="user_789")

# Next prompt is more advanced
```

---

## üß™ Testing

### Run All Tests

```bash
# Quick test (recommended)
python test_all_experiments_simple.py

# Comprehensive test
python test_all_experiments.py

# Individual experiment
pytest tests/test_lifelong_learning.py -v
```

### Expected Results

```
‚úÖ Lifelong Learning Agent - PASSED
‚úÖ Multi-Agent Workspace - PASSED
‚úÖ Temporal Reasoning - PASSED
‚úÖ Personalized Tutor - PASSED
‚úÖ Contextual Copilot - PASSED
‚úÖ Memory-Aware RAG - PASSED
‚ö†Ô∏è Adaptive Prompts - REQUIRES LLM API KEY

Overall: 6/7 passing (85.7%)
```

---

## üîß Configuration

### Environment Variables

```bash
# Optional: For LLM-based experiments
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Database (default: SQLite in-memory)
DATABASE_URL=postgresql://localhost/lltm

# Logging
LOG_LEVEL=INFO
```

### Custom Configuration

```python
# Use persistent storage
store = SQLiteGraphStore("my_experiments.db")

# Enable verbose logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Configure pipeline
pipeline = MemoryPipeline(
    store=store,
    enable_conflict_detection=True,
    enable_temporal_decay=True
)
```

---

## üìä Performance

### Latency
- **Lifelong Learning**: ~5ms per operation
- **Multi-Agent**: ~10ms per agent interaction
- **Temporal Reasoning**: ~3ms per decay calculation
- **Personalized Tutor**: ~8ms per recommendation
- **Contextual Copilot**: ~6ms per suggestion
- **Memory-Aware RAG**: ~15ms per query (includes retrieval)
- **Adaptive Prompts**: ~12ms per prompt generation

### Scalability
- All experiments tested with 1000+ operations
- Linear scaling with memory size
- Efficient conflict detection (<5ms overhead)

---

## üéì Learning Path

**Recommended order for exploring experiments:**

1. **Start**: Lifelong Learning Agent (simplest)
2. **Next**: Temporal Reasoning (core concept)
3. **Then**: Multi-Agent Workspace (collaboration)
4. **Advanced**: Personalized Tutor (adaptive systems)
5. **Expert**: Memory-Aware RAG (integration)
6. **Bonus**: Contextual Copilot, Adaptive Prompts

---

## üí° Building Your Own Experiment

### Template

```python
from src.pipeline.memory_pipeline import MemoryPipeline
from src.storage.sqlite_store import SQLiteGraphStore

class MyExperiment:
    def __init__(self, user_id: str, pipeline: MemoryPipeline):
        self.user_id = user_id
        self.pipeline = pipeline
    
    async def process(self, input_data: str):
        # Your logic here
        await self.pipeline.process_message(input_data, user_id=self.user_id)
    
    async def query(self, query: str):
        # Retrieve relevant memories
        atoms = await self.pipeline.store.get_atoms_by_subject(
            self.user_id,
            graph=GraphType.SUBSTANTIATED
        )
        return atoms

# Use it
async def main():
    store = SQLiteGraphStore(":memory:")
    await store.connect()
    pipeline = MemoryPipeline(store)
    
    experiment = MyExperiment("user_123", pipeline)
    await experiment.process("Some input")
    results = await experiment.query("Some query")
    print(results)
```

---

## üìö Additional Resources

- **Architecture**: `../architecture/TECHNICAL_DESIGN.md`
- **API Reference**: `../api/REFERENCE.md`
- **Benchmarks**: `../benchmarks/COMPREHENSIVE_RESULTS.md`
- **Deployment**: `../deployment/GUIDE.md`

---

## üêõ Troubleshooting

### Common Issues

**1. Import Errors**
```bash
# Make sure you're in the project root
cd /path/to/LLTM

# Install dependencies
pip install -r requirements.txt
```

**2. Database Errors**
```python
# Use in-memory database for testing
store = SQLiteGraphStore(":memory:")

# Or persistent database
store = SQLiteGraphStore("experiments.db")
```

**3. LLM API Errors**
```bash
# Set API key
export OPENAI_API_KEY=sk-...

# Or skip LLM-dependent experiments
python test_all_experiments_simple.py  # Skips adaptive prompts
```

---

## üéØ Next Steps

1. **Run experiments**: `python test_all_experiments_simple.py`
2. **Explore code**: Check `src/agents/` directory
3. **Build your own**: Use template above
4. **Deploy**: See `../deployment/GUIDE.md`

---

**Status**: 6/7 experiments working ‚úÖ  
**Last Updated**: January 31, 2026
